{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyMV71XZTeAN"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.10.0\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load TFWhisperForConditionalGeneration"
      ],
      "metadata": {
        "id": "ItgIfqs_UJk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperProcessor, WhisperFeatureExtractor, TFWhisperForConditionalGeneration\n",
        "import wave\n",
        "import numpy as np\n",
        "from scipy.signal import resample\n",
        "from datasets import load_dataset\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
        "model = TFWhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
        "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"ko\", task=\"transcribe\")\n",
        "forced_decoder_ids"
      ],
      "metadata": {
        "id": "UypnQTHeT3qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load sample data"
      ],
      "metadata": {
        "id": "00ExtLhuUMmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with wave.open('/content/output.wav', 'rb') as wav_file:\n",
        "    print(\"channel:\", wav_file.getnchannels())\n",
        "    print(\"sample rate:\", wav_file.getframerate())\n",
        "    print(\"frames:\", wav_file.getnframes())\n",
        "    sr = wav_file.getframerate()\n",
        "    frames = wav_file.readframes(wav_file.getnframes())\n",
        "    audio_data = np.frombuffer(frames, dtype=np.int16)\n",
        "\n",
        "target_sample_rate = 16000\n",
        "if sr != 16000:\n",
        "    number_of_samples = round(len(audio_data) * float(target_sample_rate) / sr)\n",
        "    audio_data = resample(audio_data, number_of_samples).astype(np.float32)\n",
        "\n",
        "inputs = processor(audio_data, sampling_rate=target_sample_rate,\n",
        "                   return_tensors=\"np\",\n",
        "                   do_normalize = True)\n",
        "\n",
        "input_features = inputs.input_features\n",
        "print(input_features.shape)"
      ],
      "metadata": {
        "id": "cFOLsNy7UEQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test generate Korean Transcribe"
      ],
      "metadata": {
        "id": "JBkmfO4bUsVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_map = [50258, 50264, 50359, 50363] # korean, transcribe\n",
        "decoder_input_ids = np.array([token_map])\n",
        "\n",
        "encoder_outputs = model.model.encoder(input_features)\n",
        "encoder_outputs[0]\n",
        "dout = model.model.decoder(input_ids= decoder_input_ids, encoder_hidden_states=encoder_outputs[0])\n",
        "lm_logits = tf.matmul(dout[0], model.get_output_embeddings().weights, transpose_b=True)\n",
        "np.concatenate((decoder_input_ids[:,:1], np.argmax(lm_logits, axis = -1)), axis = -1)"
      ],
      "metadata": {
        "id": "4lo0aesVUDYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GenerateModel save"
      ],
      "metadata": {
        "id": "QTYSV4qTVYiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenerateModel(tf.Module):\n",
        "    def __init__(self, model):\n",
        "        super(GenerateModel, self).__init__()\n",
        "        self.model = model\n",
        "\n",
        "    @tf.function(input_signature=[\n",
        "        tf.TensorSpec(shape=[1, 80, 3000], dtype=tf.float32, name=\"input_features\"),\n",
        "        tf.TensorSpec(shape=[1, None], dtype=tf.int32, name=\"decoder_input_ids\")\n",
        "    ])\n",
        "    def serving(self, input_features, decoder_input_ids):\n",
        "        encoder_outputs = self.model.model.encoder(input_features)\n",
        "        lookup = self.model.get_output_embeddings().weights[0]\n",
        "\n",
        "        def condition(decoder_input_ids):\n",
        "            return tf.not_equal(decoder_input_ids[0, -1], 50257)\n",
        "\n",
        "        def body(decoder_input_ids):\n",
        "            dout = self.model.model.decoder(input_ids=decoder_input_ids, encoder_hidden_states=encoder_outputs[0])\n",
        "            lm_logits = tf.matmul(dout[0], lookup, transpose_b=True)\n",
        "            predicted_ids = tf.argmax(lm_logits, axis=-1, output_type=tf.int32)\n",
        "            decoder_input_ids = tf.concat([decoder_input_ids, predicted_ids[:, -1:]], axis=-1)\n",
        "            return decoder_input_ids\n",
        "\n",
        "        decoder_input_ids = tf.while_loop(condition, body, [decoder_input_ids], shape_invariants=[tf.TensorShape([1, None])])\n",
        "        return {\"seq\": tf.identity(decoder_input_ids)}\n",
        "\n",
        "saved_model_dir = 'tf_whisper'\n",
        "generate_model = GenerateModel(model=model)\n",
        "tf.saved_model.save(generate_model, saved_model_dir, signatures={\"serving_default\": generate_model.serving})\n"
      ],
      "metadata": {
        "id": "YfUzYMYaVVkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert saved model to TFLite model\n"
      ],
      "metadata": {
        "id": "1CUoSF3cV9ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model_path = 'whisper_tiny_gen.tflite'\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.experimental_new_converter = True\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "F-N0Jm-kV89S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate from TFLite model"
      ],
      "metadata": {
        "id": "yaheO8PtWY9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(input_details[0]['shape'])\n",
        "print(input_details[1]['shape'])\n",
        "print(output_details[0]['shape'])\n",
        "\n",
        "# decoder token with language, task\n",
        "token_map = [50258, 50264, 50359, 50363]\n",
        "decoder_input_ids = np.array([token_map])\n",
        "\n",
        "decoder_input_ids = np.array([token_map]).astype(np.int32)\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], decoder_input_ids.shape)\n",
        "interpreter.allocate_tensors()\n",
        "interpreter.set_tensor(input_details[1]['index'], input_features)\n",
        "interpreter.set_tensor(input_details[0]['index'], decoder_input_ids)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "output_data"
      ],
      "metadata": {
        "id": "Cf9XS66kWUtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decode\n",
        "transcription = processor.decode(output_data[0,0], skip_special_tokens=True)\n",
        "transcription"
      ],
      "metadata": {
        "id": "j6Ezw0bcXqVE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}